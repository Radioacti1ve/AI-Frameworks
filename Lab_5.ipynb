{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "226339f9-746c-42ed-b737-452a2cdea1eb",
   "metadata": {},
   "source": [
    "# Лабораторная работа №5 (Проведение исследований с градиентным бустингом)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9507d70a-fc6a-4a6c-a16e-c37bb8f847b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "pd.options.display.max_columns = 999\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83114977-bed7-4f80-a25c-d752e7196a15",
   "metadata": {},
   "source": [
    "# 1. Выбор начальных условий"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8049a52e-941a-4018-83da-586d5086b76f",
   "metadata": {},
   "source": [
    "### a. Выбрать набор данных для задачи классификации - Задача по оценке Качества вина\n",
    "1 - fixed acidity - фиксированная кислотность\\\n",
    "2 - volatile acidity - летучая кислотность\\\n",
    "3 - citric acid - лимонная кислота\\\n",
    "4 - residual sugar - остаточный сахар\\\n",
    "5 - chlorides - хлориды\\\n",
    "6 - free sulfur dioxide - свободный диоксид серы\\\n",
    "7 - total sulfur dioxide - общий диоксид серы\\\n",
    "8 - density - плотность\\\n",
    "9 - pH\\\n",
    "10 - sulphates - сульфаты\\\n",
    "11 - alcohol - спирт\\\n",
    "Выходная переменная (на основе сенсорных данных):\\\n",
    "12 - quality - качество (оценка от 0 до 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a5e756-0d23-4643-9cfc-562d53e23184",
   "metadata": {},
   "source": [
    "### b.Выбрать набор данных для задачи регрессии - Задача по предсказанию баллов за экзамен у студентов\n",
    "1 - student_id - ID студента\\\n",
    "2 - age - возраст\\\n",
    "3 - gender - пол\\\n",
    "4 - major - специальность\\\n",
    "5 - study_hours_per_day - учебные часы в день\\\n",
    "6 - social_media_hours - часы в соцсетях\\\n",
    "7 - netflix_hours - часы просмотра Netflix\\\n",
    "8 - part_time_job - подработка\\\n",
    "9 - attendance_percentage - процент посещаемости\\\n",
    "10 - sleep_hours - часы сна\\\n",
    "11 - diet_quality - качество питания\\\n",
    "12 - exercise_frequency - частота занятий спортом\\\n",
    "13 - parental_education_level - уровень образования родителей\\\n",
    "14 - internet_quality - качество интернета\\\n",
    "15 - mental_health_rating - оценка психического здоровья\\\n",
    "16 - extracurricular_participation - участие во внеурочной деятельности\\\n",
    "17 - previous_gpa - предыдущий средний балл\\\n",
    "18 - semester - семестр\\\n",
    "19 - stress_level - уровень стресса\\\n",
    "20 - dropout_risk - риск отчисления\\\n",
    "21 - social_activity - социальная активность\\\n",
    "22 - screen_time - время у экрана\\\n",
    "23 - study_environment - учебная среда\\\n",
    "24 - access_to_tutoring - доступ к репетиторству\\\n",
    "25 - family_income_range - диапазон дохода семьи\\\n",
    "26 - parental_support_level - уровень поддержки родителей\\\n",
    "27 - motivation_level - уровень мотивации\\\n",
    "28 - exam_anxiety_score - балл тревожности на экзаменах\\\n",
    "29 - learning_style - стиль обучения\\\n",
    "30 - time_management_score - балл управления временем\\\n",
    "Выходная переменная:\\\n",
    "31 - exam_score - оценка за экзамен\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64f9acac-ed58-400d-8540-9e6c88be50b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wine_data = pd.read_csv('data/classification/WineQT.csv').set_index('Id')\n",
    "Student_data = pd.read_csv('data/Regression/enhanced_student.csv').set_index('student_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8555458c-7ebb-44e1-b22c-865098ade4f4",
   "metadata": {},
   "source": [
    "### c. Выбрать метрики качества и обосновать их выбор"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d72837-20a1-4d5d-8262-91d19c4e0231",
   "metadata": {},
   "source": [
    "#### Метрики выбранные для Датасета про Качество вина (Классификация):\n",
    "1.Accuracy - Самая базовая метрика, доля правильно предсказанных. Если классы сбалансированы\\\n",
    "2.Precision-weighted - если важно не завышать оценки\\\n",
    "3.recall-weighted - если важно не занижать оценки\\\n",
    "4.F1-score (weighted) - Метрика для случая если целевая переменная имеет сильный дисбаланс классов, баланс precision/recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547fa787-523a-4131-82fc-519a1358ccd7",
   "metadata": {},
   "source": [
    "#### Метрики выбранные для Датасета про студентов (Регрессии):\n",
    "1.MAE (Mean Absolute Error) - интерпретируем в исходных единицах\\\n",
    "2.RMSE (Root Mean Square Error) - штрафует за большие ошибки\\\n",
    "3.MAPE (Mean Absolute Percentage Error) - относительная ошибка в %"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034b1f07-3b0f-4a5f-810f-aaaae50da25f",
   "metadata": {},
   "source": [
    "# 2.Создание бейзлайна и оценка качества"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc99038-a07b-4045-a7a4-d2b28772e5f3",
   "metadata": {},
   "source": [
    "Перед началом создания и обучения моделей закодируем данные в Датасете студентов для корректной работы моделей sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e932b882-c418-4b3e-8345-e13849f040ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = Student_data.select_dtypes(include=['object']).columns # Берём все категориальные данные\n",
    "\n",
    "binary_cols = [col for col in categorical_cols if Student_data[col].nunique() == 2] # Разделяем на бинарные и небинарные\n",
    "non_binary_cols = [col for col in categorical_cols if Student_data[col].nunique() > 2]\n",
    "Student_data = pd.get_dummies(Student_data, columns=binary_cols, drop_first=True) # get_dummies для бинарных\n",
    "\n",
    "if non_binary_cols:\n",
    "    encoder = OrdinalEncoder() # OrdinalEncoder для небинарных\n",
    "    Student_data[non_binary_cols] = encoder.fit_transform(Student_data[non_binary_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a58deb-fb17-42af-9660-8d9df8c2337f",
   "metadata": {},
   "source": [
    "Кодировка данных происходит благодаря get_dummies и OrdinalEncoder, первые используем для кодировки бинарных признаков, второй это базовый энкодер который используется для небинарных признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af07f566-5475-47a5-99cb-df91ece8568a",
   "metadata": {},
   "source": [
    "### a.Обучить модели из sklearn (для классификации и регрессии) для выбранных наборов данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ddfa77-13b6-46bd-8c0b-b7b464f321fb",
   "metadata": {},
   "source": [
    "Разделим данные на X - признаки и Y - Целевая"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99600d1c-631a-44a7-a5bf-77ab86d742aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Wine = Wine_data.drop(['quality'], axis = 1)\n",
    "y_Wine = Wine_data['quality']\n",
    "\n",
    "X_Student = Student_data.drop(['exam_score'], axis = 1)\n",
    "y_Student = Student_data['exam_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0b2137-7d85-4566-b292-d4fcffb5100a",
   "metadata": {},
   "source": [
    "разделим данные на обучающую и тестовую выборку при помощи train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "591972b3-f088-4d5c-9473-a0c21bfca7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_Student, X_test_Student, y_train_Student, y_test_Student = train_test_split(X_Student, y_Student, test_size=0.33, random_state=42)\n",
    "X_train_Wine, X_test_Wine, y_train_Wine, y_test_Wine = train_test_split(X_Wine, y_Wine, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32050208-7359-44e1-a8c7-627d8df6df92",
   "metadata": {},
   "source": [
    "Создадим и обучим модель на разделённых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4bfa36c5-cc71-4763-a51a-f8eb5c7a8331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GB_Wine = GradientBoostingClassifier()\n",
    "GB_student = GradientBoostingRegressor()\n",
    "\n",
    "GB_Wine.fit(X_train_Wine, y_train_Wine)\n",
    "GB_student.fit(X_train_Student, y_train_Student)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01190d8-f208-4e1a-9e25-96951ae0c116",
   "metadata": {},
   "source": [
    "После обучения обоих моделей выведем все метрики на экран и сделаем выводы по работе моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e36e7c3-896b-4277-9b90-f05445d5f31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики Классификации качества Вина:\n",
      "Accuracy:  0.6322751322751323 \n",
      "Recall:    0.6322751322751323 \n",
      "Precision: 0.6413018921598186 \n",
      "F1:        0.6364684877312211\n",
      "=====================================\n",
      "Метрики Регрессии по экзаменам студентов:\n",
      "MAE:  3.2308063314467366 \n",
      "RMSE: 4.1666085771370245 \n",
      "MAPE: 0.03840411710960138\n"
     ]
    }
   ],
   "source": [
    "Wine_predict = GB_Wine.predict(X_test_Wine)\n",
    "Student_predict = GB_student.predict(X_test_Student)\n",
    "\n",
    "print('Метрики Классификации качества Вина:')\n",
    "print(f'Accuracy:  {accuracy_score(y_test_Wine, Wine_predict)} \\n'\n",
    "      f'Recall:    {recall_score(y_test_Wine, Wine_predict, average=\"weighted\")} \\n'\n",
    "      f'Precision: {precision_score(y_test_Wine, Wine_predict, average=\"weighted\", zero_division=True)} \\n'\n",
    "      f'F1:        {f1_score(y_test_Wine, Wine_predict, average=\"weighted\")}')\n",
    "print('=====================================')\n",
    "print('Метрики Регрессии по экзаменам студентов:')\n",
    "print(f'MAE:  {mean_absolute_error(y_test_Student, Student_predict)} \\n'\n",
    "      f'RMSE: {np.sqrt(mean_squared_error(y_test_Student, Student_predict))} \\n'\n",
    "      f'MAPE: {mean_absolute_percentage_error(y_test_Student, Student_predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b11e8f-bd59-4683-951c-433773a9d2ca",
   "metadata": {},
   "source": [
    "### Метрики Классификации качества Вина\n",
    "Градиентный бустинг справился ожидаемо неплохо в сравнении с другими моделями, но всё же хуже Случайного леса. Данный ансамбль правильно предугадал 0.63 долю правильно"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1725dc-268c-43bb-b9e6-5b04dad2fa8c",
   "metadata": {},
   "source": [
    "### Метрики Регрессии по экзаменам студентов\n",
    "С регрессией тоже очень хорошо, модель смогла получить метрики даже лучше Случайного леса"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a00360-a15c-4470-b4f8-8850019702da",
   "metadata": {},
   "source": [
    "# 3.Улучшение бейзлайна"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eab1fd5-d929-4948-bf8a-92a45a818671",
   "metadata": {},
   "source": [
    "##### Для задачии Классификации (Оценка качества вина) сделаем следующее:\n",
    "- Устраним дисбаланс классов\n",
    "- Проведём масштабированние данных\n",
    "##### Для задачии Регрессии (Предсказать оценку студента) сделаем следующее:\n",
    "- Проведём масштабированние данных\n",
    "##### Для модели сделаем следующее:\n",
    "- Подберём Гиперпараметры через GridSearchCV\n",
    "- Применим Кросс-валидацию при обучении модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5127698-4017-4c39-aaec-44a363bf3d12",
   "metadata": {},
   "source": [
    "### Препроцессинг данных Классификации Вина"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464b96ff-331f-405a-b4bb-d22975717ca6",
   "metadata": {},
   "source": [
    "Для начала обработаем данные классификации избавившись от дисбаланса при помощи SMOTE (Synthetic Minority Over-sampling Technique) и снова выведем график распределения целевой, а далее применим масштабированние"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3966685-6d98-4e75-a531-ac6c58c00ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42, k_neighbors=4)\n",
    "X_train_wine_smote, y_train_wine_smote = smote.fit_resample(X_train_Wine, y_train_Wine)\n",
    "\n",
    "class_counts = pd.Series(y_train_wine_smote).value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=class_counts.index, y=class_counts.values)\n",
    "plt.title('Распределение классов')\n",
    "plt.xlabel('Классы')\n",
    "plt.ylabel('Количество')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d2b9bf-2776-4028-8dfb-bfa91becf321",
   "metadata": {},
   "source": [
    "Как заметно на графике, дисбаланс классов был полностью устранён, далее промасштабируем данные, это очень важно для моделей которые работают с расстоянием в данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83b83146-397b-439c-9e89-50f4d3306e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler_wine = StandardScaler()\n",
    "X_train_wine_smote_scale = Scaler_wine.fit_transform(X_train_wine_smote)\n",
    "X_test_Wine_scale = Scaler_wine.transform(X_test_Wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2549f35d-16c0-4e3b-aa8d-4b920900b1fd",
   "metadata": {},
   "source": [
    "Масштабируем данные ОБЯЗАТЕЛЬНО после train_test_split чтобы не было утечки данных в тестовую выборку и модель показывала корректные метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce339cb1-1441-4f66-9692-b71ba58721dc",
   "metadata": {},
   "source": [
    "### Препроцессинг данных Регрессии Результаты студентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fff8fb94-6be4-4e2c-af86-8eb7a7b5d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler_student = StandardScaler()\n",
    "X_train_Student_scale = Scaler_student.fit_transform(X_train_Student)\n",
    "X_test_Student_scale = Scaler_student.transform(X_test_Student)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5155ca71-570b-42c8-aaea-b8d54a6d3a1f",
   "metadata": {},
   "source": [
    "### Создание моделей, обучение на обработанных данных и применение GridSearchCV для подбора гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "adb89124-ae4a-47f6-95b5-1d778028e1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingClassifier(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.05, 0.05], &#x27;max_depth&#x27;: [2, None],\n",
       "                         &#x27;min_samples_split&#x27;: [1, 3, 5]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingClassifier(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.05, 0.05], &#x27;max_depth&#x27;: [2, None],\n",
       "                         &#x27;min_samples_split&#x27;: [1, 3, 5]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingClassifier(),\n",
       "             param_grid={'learning_rate': [0.05, 0.05], 'max_depth': [2, None],\n",
       "                         'min_samples_split': [1, 3, 5]})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GB_params_wine = {\n",
    "    'learning_rate': [0.05, 0.05],\n",
    "    'max_depth': [2, None],\n",
    "    'min_samples_split': [1, 3, 5],\n",
    "}\n",
    "\n",
    "GB_wine = GradientBoostingClassifier()\n",
    "GB_wine_grid = GridSearchCV(estimator=GB_wine, param_grid=GB_params_wine, cv=5)\n",
    "GB_wine_grid.fit(X_train_wine_smote_scale, y_train_wine_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "97f3d075-9348-4389-b699-7174b653f625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingRegressor(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.05, 0.05], &#x27;max_depth&#x27;: [2, None],\n",
       "                         &#x27;min_samples_split&#x27;: [1, 3, 5]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingRegressor(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.05, 0.05], &#x27;max_depth&#x27;: [2, None],\n",
       "                         &#x27;min_samples_split&#x27;: [1, 3, 5]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingRegressor(),\n",
       "             param_grid={'learning_rate': [0.05, 0.05], 'max_depth': [2, None],\n",
       "                         'min_samples_split': [1, 3, 5]})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GB_params_student = {\n",
    "    'learning_rate': [0.05, 0.05],\n",
    "    'max_depth': [2, None],\n",
    "    'min_samples_split': [1, 3, 5],\n",
    "}\n",
    "\n",
    "GB_student = GradientBoostingRegressor()\n",
    "GB_student_grid = GridSearchCV(estimator=GB_student, param_grid=GB_params_student, cv=5)\n",
    "GB_student_grid.fit(X_train_Student_scale, y_train_Student)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9ef4d1-bac8-4e92-82a0-56c3211abb39",
   "metadata": {},
   "source": [
    "После успешного обучения моделей, выведем метрики нового бейзлайна и сравним результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d3d3c511-08b4-4cc9-8dba-30fe69c589d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики Классификации качества Вина на новом бейзлайне:\n",
      "Accuracy:  0.5343915343915344 \n",
      "Recall:    0.5343915343915344 \n",
      "Precision: 0.5747893451975086 \n",
      "F1:        0.5522894698348104\n",
      "=====================================\n",
      "Метрики Регрессии по экзаменам студентов на новом бейзлайне:\n",
      "MAE:  3.2397002200340297 \n",
      "RMSE: 4.165610179707074 \n",
      "MAPE: 0.038515946218849934\n"
     ]
    }
   ],
   "source": [
    "Wine_predict = GB_wine_grid.predict(X_test_Wine_scale)\n",
    "Student_predict = GB_student_grid.predict(X_test_Student_scale)\n",
    "\n",
    "print('Метрики Классификации качества Вина на новом бейзлайне:')\n",
    "print(f'Accuracy:  {accuracy_score(y_test_Wine, Wine_predict)} \\n'\n",
    "      f'Recall:    {recall_score(y_test_Wine, Wine_predict, average=\"weighted\")} \\n'\n",
    "      f'Precision: {precision_score(y_test_Wine, Wine_predict, average=\"weighted\")} \\n'\n",
    "      f'F1:        {f1_score(y_test_Wine, Wine_predict, average=\"weighted\")}')\n",
    "print('=====================================')\n",
    "print('Метрики Регрессии по экзаменам студентов на новом бейзлайне:')\n",
    "print(f'MAE:  {mean_absolute_error(y_test_Student, Student_predict)} \\n'\n",
    "      f'RMSE: {np.sqrt(mean_squared_error(y_test_Student, Student_predict))} \\n'\n",
    "      f'MAPE: {mean_absolute_percentage_error(y_test_Student, Student_predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f5ca89-88a9-465d-8bfb-4d47300971f1",
   "metadata": {},
   "source": [
    "### Метрики Классификации качества Вина на новом бейзлайне\n",
    "Все метрики упали примерно на целых 0.1, что является довольно плохим результатом. Гиперпараметры ставили чуть больше и чуть меньше изначальных значений, чтобы попытаться найти более оптимальные, но оптимальными оказались базовые гиперпараметры."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd6db03-b099-467b-8ce3-534cb3e7f8f1",
   "metadata": {},
   "source": [
    "### Метрики Регрессии по экзаменам студентов на новом бейзлайне\n",
    "Метрики регрессии в свою очередь никак не поменялись."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b2928e-b93b-475d-9039-5362634f8859",
   "metadata": {},
   "source": [
    "# 4.Имплементация алгоритма машинного обучения "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4851e5b0-2d43-46a3-947d-0c160b5b47de",
   "metadata": {},
   "source": [
    "### a. Самостоятельно имплементировать алгоритмы машинного обучения (для классификации и регрессии)\n",
    "- Модель Дерева решений для классификации - Задача классификации качества вина"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c2a3697-9f90-4da6-84ae-148bb14f2207",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurDecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=5, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree_ = None\n",
    "        self.classes_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Преобразуем в numpy arrays\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        \n",
    "        # Сохраняем уникальные классы и создаем mapping\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        \n",
    "        # Создаем mapping из исходных меток в индексы 0..n_classes-1\n",
    "        self.class_to_index_ = {cls: i for i, cls in enumerate(self.classes_)}\n",
    "        y_encoded = np.array([self.class_to_index_[cls] for cls in y])\n",
    "        \n",
    "        self.tree_ = self._grow_tree(X, y_encoded)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X)\n",
    "        encoded_predictions = np.array([self._predict(x) for x in X])\n",
    "        # Преобразуем обратно в исходные метки\n",
    "        return np.array([self.classes_[idx] for idx in encoded_predictions])\n",
    "\n",
    "    def _gini(self, y):\n",
    "        m = len(y)\n",
    "        if m == 0:\n",
    "            return 0\n",
    "        return 1.0 - sum((np.sum(y == c) / m) ** 2 for c in range(self.n_classes_))\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        m, n = X.shape\n",
    "        if m <= 1:\n",
    "            return None, None\n",
    "\n",
    "        num_parent = [np.sum(y == c) for c in range(self.n_classes_)]\n",
    "        best_gini = 1.0 - sum((num / m) ** 2 for num in num_parent)\n",
    "        best_idx, best_thr = None, None\n",
    "\n",
    "        for idx in range(n):\n",
    "            # Используем argsort для эффективного получения отсортированных значений\n",
    "            sort_idx = np.argsort(X[:, idx])\n",
    "            thresholds = X[sort_idx, idx]\n",
    "            classes = y[sort_idx]\n",
    "            \n",
    "            num_left = [0] * self.n_classes_\n",
    "            num_right = num_parent.copy()\n",
    "\n",
    "            for i in range(1, m):\n",
    "                c = classes[i - 1]\n",
    "                num_left[c] += 1\n",
    "                num_right[c] -= 1\n",
    "                gini_left = 1.0 - sum((x / i) ** 2 for x in num_left)\n",
    "                gini_right = 1.0 - sum((x / (m - i)) ** 2 for x in num_right)\n",
    "                gini = (i * gini_left + (m - i) * gini_right) / m\n",
    "\n",
    "                if thresholds[i] == thresholds[i - 1]:\n",
    "                    continue\n",
    "\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_idx = idx\n",
    "                    best_thr = (thresholds[i] + thresholds[i - 1]) / 2\n",
    "\n",
    "        return best_idx, best_thr\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        num_samples = len(y)\n",
    "        \n",
    "        # Находим наиболее частый класс\n",
    "        if num_samples > 0:\n",
    "            class_counts = [np.sum(y == c) for c in range(self.n_classes_)]\n",
    "            predicted_class = np.argmax(class_counts)\n",
    "        else:\n",
    "            predicted_class = 0\n",
    "        \n",
    "        node = {\n",
    "            \"predicted_class\": predicted_class,\n",
    "            \"num_samples\": num_samples,\n",
    "        }\n",
    "\n",
    "        if (self.max_depth is None or depth < self.max_depth) and num_samples >= self.min_samples_split:\n",
    "            idx, thr = self._best_split(X, y)\n",
    "            if idx is not None:\n",
    "                indices_left = X[:, idx] < thr\n",
    "                node[\"feature_index\"] = idx\n",
    "                node[\"threshold\"] = thr\n",
    "                node[\"left\"] = self._grow_tree(X[indices_left], y[indices_left], depth + 1)\n",
    "                node[\"right\"] = self._grow_tree(X[~indices_left], y[~indices_left], depth + 1)\n",
    "                \n",
    "        return node\n",
    "\n",
    "    def _predict(self, x):\n",
    "        node = self.tree_\n",
    "        while \"threshold\" in node:\n",
    "            if x[node[\"feature_index\"]] < node[\"threshold\"]:\n",
    "                node = node[\"left\"]\n",
    "            else:\n",
    "                node = node[\"right\"]\n",
    "        return node[\"predicted_class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24748db-4dd6-427b-ae7c-0989baf4a877",
   "metadata": {},
   "source": [
    "- Модель Дерева решений для Регрессии - Задача регрессионной оценки по результатам студентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a622914-510c-4f5c-bb23-fac093f7cf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurDecisionTreeRegressor:\n",
    "    def __init__(self, max_depth=5, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Преобразуем в numpy arrays\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        self.tree_ = self._grow_tree(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X)\n",
    "        return np.array([self._predict(x) for x in X])\n",
    "\n",
    "    def _mse(self, y):\n",
    "        return np.mean((y - np.mean(y)) ** 2) if len(y) > 0 else 0\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        m, n = X.shape\n",
    "        if m <= 1:\n",
    "            return None, None\n",
    "\n",
    "        best_mse = self._mse(y)\n",
    "        best_idx, best_thr = None, None\n",
    "\n",
    "        for idx in range(n):\n",
    "            # Используем argsort для эффективного получения отсортированных значений\n",
    "            sort_idx = np.argsort(X[:, idx])\n",
    "            thresholds = X[sort_idx, idx]\n",
    "            values = y[sort_idx]\n",
    "            \n",
    "            for i in range(1, m):\n",
    "                if thresholds[i] == thresholds[i - 1]:\n",
    "                    continue\n",
    "                    \n",
    "                y_left, y_right = values[:i], values[i:]\n",
    "                mse_left = self._mse(y_left)\n",
    "                mse_right = self._mse(y_right)\n",
    "                mse_total = (len(y_left) * mse_left + len(y_right) * mse_right) / m\n",
    "\n",
    "                if mse_total < best_mse:\n",
    "                    best_mse = mse_total\n",
    "                    best_idx = idx\n",
    "                    best_thr = (thresholds[i] + thresholds[i - 1]) / 2\n",
    "\n",
    "        return best_idx, best_thr\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        num_samples = len(y)\n",
    "        predicted_value = np.mean(y) if num_samples > 0 else 0\n",
    "        \n",
    "        node = {\n",
    "            \"predicted_value\": predicted_value,\n",
    "            \"num_samples\": num_samples\n",
    "        }\n",
    "\n",
    "        if (self.max_depth is None or depth < self.max_depth) and num_samples >= self.min_samples_split:\n",
    "            idx, thr = self._best_split(X, y)\n",
    "            if idx is not None:\n",
    "                indices_left = X[:, idx] < thr\n",
    "                node[\"feature_index\"] = idx\n",
    "                node[\"threshold\"] = thr\n",
    "                node[\"left\"] = self._grow_tree(X[indices_left], y[indices_left], depth + 1)\n",
    "                node[\"right\"] = self._grow_tree(X[~indices_left], y[~indices_left], depth + 1)\n",
    "                \n",
    "        return node\n",
    "\n",
    "    def _predict(self, x):\n",
    "        node = self.tree_\n",
    "        while \"threshold\" in node:\n",
    "            if x[node[\"feature_index\"]] < node[\"threshold\"]:\n",
    "                node = node[\"left\"]\n",
    "            else:\n",
    "                node = node[\"right\"]\n",
    "        return node[\"predicted_value\"]\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {\"max_depth\": self.max_depth, \"min_samples_split\": self.min_samples_split}\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for key, value in params.items():\n",
    "            setattr(self, key, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd5dd11-76a1-4d77-ae3c-77338d0c5e4b",
   "metadata": {},
   "source": [
    "- Ансамбль Градиентного бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a937ac8-c5d3-4584-bfaf-91b71bf057f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurGradientBoosting:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=5, task='reg'):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.task = task\n",
    "        self.trees = []\n",
    "        self.initial = None\n",
    "        self.classes_ = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X, y = np.asarray(X), np.asarray(y)\n",
    "        \n",
    "        if self.task == 'reg':\n",
    "            # Регрессия - простая MSE\n",
    "            self.initial = np.mean(y)\n",
    "            pred = np.full(len(y), self.initial)\n",
    "            \n",
    "            for _ in range(self.n_estimators):\n",
    "                tree = OurDecisionTreeRegressor(max_depth=self.max_depth)\n",
    "                tree.fit(X, y - pred)\n",
    "                update = tree.predict(X)\n",
    "                pred += self.learning_rate * update\n",
    "                self.trees.append(tree)\n",
    "                \n",
    "        else:\n",
    "            # Классификация - многоклассовая\n",
    "            self.classes_ = np.unique(y)\n",
    "            n_classes = len(self.classes_)\n",
    "            \n",
    "            # One-hot кодирование\n",
    "            y_oh = np.eye(n_classes)[np.searchsorted(self.classes_, y)]\n",
    "            \n",
    "            # Начальные логиты\n",
    "            self.initial = np.zeros(n_classes)\n",
    "            logits = np.zeros((len(y), n_classes))\n",
    "            \n",
    "            for _ in range(self.n_estimators):\n",
    "                # Softmax вероятности\n",
    "                exp_logits = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
    "                probs = exp_logits / np.sum(exp_logits, axis=1, keepdims=True)\n",
    "                \n",
    "                # Градиенты\n",
    "                grads = y_oh - probs\n",
    "                \n",
    "                # Деревья для каждого класса\n",
    "                trees_iter = []\n",
    "                for k in range(n_classes):\n",
    "                    tree = OurDecisionTreeRegressor(max_depth=self.max_depth)\n",
    "                    tree.fit(X, grads[:, k])\n",
    "                    trees_iter.append(tree)\n",
    "                    logits[:, k] += self.learning_rate * tree.predict(X)\n",
    "                \n",
    "                self.trees.append(trees_iter)\n",
    "                \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X)\n",
    "        \n",
    "        if self.task == 'reg':\n",
    "            pred = np.full(len(X), self.initial)\n",
    "            for tree in self.trees:\n",
    "                pred += self.learning_rate * tree.predict(X)\n",
    "            return pred\n",
    "            \n",
    "        else:\n",
    "            # Для классификации используем predict_proba\n",
    "            proba = self.predict_proba(X)\n",
    "            return self.classes_[np.argmax(proba, axis=1)]\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        if self.task == 'reg':\n",
    "            raise ValueError(\"Только для классификации\")\n",
    "            \n",
    "        X = np.asarray(X)\n",
    "        n_classes = len(self.classes_)\n",
    "        logits = np.zeros((len(X), n_classes))\n",
    "        \n",
    "        for trees_iter in self.trees:\n",
    "            for k, tree in enumerate(trees_iter):\n",
    "                logits[:, k] += self.learning_rate * tree.predict(X)\n",
    "        \n",
    "        # Softmax\n",
    "        exp_logits = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
    "        return exp_logits / np.sum(exp_logits, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9ae4bf-65d0-48be-a95b-a883cc74090f",
   "metadata": {},
   "source": [
    "### b. Обучить имплементированные модели (для классификации и регрессии) для выбранных наборов данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "432d0da6-1239-490d-b9fe-784e116d7630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.OurGradientBoosting at 0x227e650b7d0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_wine = OurGradientBoosting(task='class')\n",
    "gb_Student = OurGradientBoosting()\n",
    "\n",
    "gb_wine.fit(X_train_Wine, y_train_Wine)\n",
    "gb_Student.fit(X_train_Student, y_train_Student)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d3873a-e491-4262-9645-bd1fd02cbbcb",
   "metadata": {},
   "source": [
    "### c. Оценить качество имплементированных моделей (для классификации и регрессии) по выбранным метрикам на выбранных наборах данных\n",
    "### d. Сравнить результаты имплементированных моделей в сравнении с результатами из пункта 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22af896f-6aff-4674-9337-58ffda27cc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики Классификации качества Вина:\n",
      "Accuracy:  0.6164021164021164 \n",
      "Recall:    0.6164021164021164 \n",
      "Precision: 0.6035967006495462 \n",
      "F1:        0.6068773901917941\n",
      "=====================================\n",
      "Метрики Регрессии по экзаменам студентов:\n",
      "MAE:  3.2309488997192455 \n",
      "RMSE: 4.166515921869482 \n",
      "MAPE: 0.038402129726107216\n"
     ]
    }
   ],
   "source": [
    "Wine_predict = gb_wine.predict(X_test_Wine)\n",
    "Student_predict = gb_Student.predict(X_test_Student)\n",
    "\n",
    "print('Метрики Классификации качества Вина:')\n",
    "print(f'Accuracy:  {accuracy_score(y_test_Wine, Wine_predict)} \\n'\n",
    "      f'Recall:    {recall_score(y_test_Wine, Wine_predict, average=\"weighted\")} \\n'\n",
    "      f'Precision: {precision_score(y_test_Wine, Wine_predict, average=\"weighted\", zero_division=True)} \\n'\n",
    "      f'F1:        {f1_score(y_test_Wine, Wine_predict, average=\"weighted\")}')\n",
    "print('=====================================')\n",
    "print('Метрики Регрессии по экзаменам студентов:')\n",
    "print(f'MAE:  {mean_absolute_error(y_test_Student, Student_predict)} \\n'\n",
    "      f'RMSE: {np.sqrt(mean_squared_error(y_test_Student, Student_predict))} \\n'\n",
    "      f'MAPE: {mean_absolute_percentage_error(y_test_Student, Student_predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74acef40-e57c-4095-8fc4-9c8297d3f4bc",
   "metadata": {},
   "source": [
    "### Метрики Имплементированной модели - Классификации качества Вина на первом бейзлайне\n",
    "Метрики Имплементированной модели на базовой модели показали себя очень достойно. Модель из sklearn на базовом безлайне показала себя немного лучше, но данная модель так же справилась достойно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3644d6-f515-4d48-a108-c97ef2f196a4",
   "metadata": {},
   "source": [
    "### Метрики Имплементированной модели - Регрессии по экзаменам студентов на первом бейзлайне\n",
    "Метрики Имплементированной модели на первом бейзлайне так же как и в случае с Классификацией показали себя достойно, модель может сравнится с Линейной регрессией. Никак не отличается от своего аналога из sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04411d1-f010-4673-9665-3944b5ac1130",
   "metadata": {},
   "source": [
    "### f. Добавить техники из улучшенного бейзлайна (пункт 3с)\n",
    "- Функция для подбора гиперпараметров к модели и спользование Кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e3c466a-5fb8-491d-b658-bbd361e7efc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_cv(X, y, task, n_estimators_list=[50, 100], learning_rates=[0.01, 0.1], \n",
    "                 max_depths=[2, 3], cv=3, random_state=42, sample_ratio=1.0):\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    # Создаем param_grid из переданных параметров\n",
    "    param_grid = {\n",
    "        'n_estimators': n_estimators_list,\n",
    "        'learning_rate': learning_rates,\n",
    "        'max_depth': max_depths\n",
    "    }\n",
    "    \n",
    "    # Применяем подвыборку если нужно\n",
    "    if sample_ratio < 1.0:\n",
    "        n_samples = int(len(X) * sample_ratio)\n",
    "        rng = np.random.default_rng(random_state)\n",
    "        indices = rng.choice(len(X), n_samples, replace=False)\n",
    "        X = X[indices]\n",
    "        y = y[indices]\n",
    "        print(f\"Используется подвыборка: {n_samples} samples ({sample_ratio*100:.1f}% данных)\")\n",
    "    \n",
    "    n = X.shape[0]\n",
    "    \n",
    "    # Перемешиваем данные\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    indices = rng.permutation(n)\n",
    "    X, y = X[indices], y[indices]\n",
    "    \n",
    "    fold_size = n // cv\n",
    "    best_score = -np.inf\n",
    "    best_params = None\n",
    "    \n",
    "    # Перебираем все комбинации параметров\n",
    "    for params in [dict(zip(param_grid.keys(), values)) \n",
    "                   for values in product(*param_grid.values())]:\n",
    "        \n",
    "        scores = []\n",
    "        \n",
    "        for i in range(cv):\n",
    "            start = i * fold_size\n",
    "            end = (i + 1) * fold_size if i < cv - 1 else n\n",
    "            \n",
    "            # Разделяем на train/val\n",
    "            X_val, y_val = X[start:end], y[start:end]\n",
    "            X_train = np.concatenate([X[:start], X[end:]])\n",
    "            y_train = np.concatenate([y[:start], y[end:]])\n",
    "            \n",
    "            # Создаем и обучаем модель\n",
    "            model = OurGradientBoosting(task=task, **params)\n",
    "            model.fit(X_train, y_train)\n",
    "            preds = model.predict(X_val)\n",
    "            \n",
    "            # Вычисляем score в зависимости от типа задачи\n",
    "            if task == \"classification\" or task == \"class\":\n",
    "                score = np.mean(preds == y_val)  # accuracy\n",
    "            else:\n",
    "                score = -np.mean((preds - y_val)**2)  # отрицательный MSE\n",
    "            \n",
    "            scores.append(score)\n",
    "        \n",
    "        avg_score = np.mean(scores)\n",
    "        \n",
    "        if avg_score > best_score:\n",
    "            best_score = avg_score\n",
    "            best_params = params\n",
    "    \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bb8467-2739-4c21-afca-3123131d8c1a",
   "metadata": {},
   "source": [
    "### g. Обучить модели (для классификации и регрессии) для выбранных наборов данных\n",
    "- Поиск гиперпараметров для Классификации и Регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e18dfe3-02d6-4836-a9ea-acbab3646ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_wine = gb_cv(X_train_wine_smote_scale, y_train_wine_smote, task=\"class\", n_estimators_list =[50, 130],max_depths = [3, 7], learning_rates = [0.01, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "11bf8426-32e7-447f-bba6-fc097f2fbf24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используется подвыборка: 13400 samples (25.0% данных)\n"
     ]
    }
   ],
   "source": [
    "best_params_Student = gb_cv(X_train_Student_scale, y_train_Student, task=\"reg\", n_estimators_list = [50, 130],max_depths = [3, 7], learning_rates = [0.01, 0.5], sample_ratio=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a26af2d6-6d07-48fe-a757-87f0f0f468e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры для Градиентного бустинга в задаче с классификацией вина: {'n_estimators': 130, 'learning_rate': 0.5, 'max_depth': 7}\n",
      "Лучшие параметры для Градиентного бустинга в задаче с регрессией оценок студентов: {'n_estimators': 50, 'learning_rate': 0.5, 'max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "print(f'Лучшие параметры для Градиентного бустинга в задаче с классификацией вина: {best_params_wine}')\n",
    "print(f'Лучшие параметры для Градиентного бустинга в задаче с регрессией оценок студентов: {best_params_Student}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ef3a02-e14b-43a3-956a-845b7f4c3d41",
   "metadata": {},
   "source": [
    "- Обучение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "048b0f3a-6dce-4e97-94ba-3d2548aca35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.OurGradientBoosting at 0x1b295fb7a10>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GB_wine = OurGradientBoosting(n_estimators=best_params_wine['n_estimators'], learning_rate=best_params_wine['learning_rate'], max_depth=best_params_wine['max_depth'], task=\"class\")\n",
    "\n",
    "GB_Student = OurGradientBoosting(n_estimators=best_params_Student['n_estimators'], learning_rate=best_params_Student['learning_rate'], max_depth=best_params_Student['max_depth'], task=\"reg\")\n",
    "\n",
    "GB_wine.fit(X_train_wine_smote_scale, y_train_wine_smote)\n",
    "GB_Student.fit(X_train_Student_scale, y_train_Student)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490af438-0738-4519-ae1a-ee352b788324",
   "metadata": {},
   "source": [
    "### h. Оценить качество моделей (для классификации и регрессии) по выбранным метрикам на выбранных наборах данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c1eda522-04c8-47da-8c91-69ecd49a7d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики Классификации качества Вина на новом бейзлайне:\n",
      "Accuracy:  0.5185185185185185 \n",
      "Recall:    0.5185185185185185 \n",
      "Precision: 0.5377365683978115 \n",
      "F1:        0.5274083916838579\n",
      "=====================================\n",
      "Метрики Регрессии по экзаменам студентов на новом бейзлайне:\n",
      "MAE:  3.245938769735733 \n",
      "RMSE: 4.192904838906656 \n",
      "MAPE: 0.038593032695779655\n"
     ]
    }
   ],
   "source": [
    "Wine_predict = GB_wine.predict(X_test_Wine_scale)\n",
    "Student_predict = GB_Student.predict(X_test_Student_scale)\n",
    "\n",
    "print('Метрики Классификации качества Вина на новом бейзлайне:')\n",
    "print(f'Accuracy:  {accuracy_score(y_test_Wine, Wine_predict)} \\n'\n",
    "      f'Recall:    {recall_score(y_test_Wine, Wine_predict, average=\"weighted\")} \\n'\n",
    "      f'Precision: {precision_score(y_test_Wine, Wine_predict, average=\"weighted\")} \\n'\n",
    "      f'F1:        {f1_score(y_test_Wine, Wine_predict, average=\"weighted\")}')\n",
    "print('=====================================')\n",
    "print('Метрики Регрессии по экзаменам студентов на новом бейзлайне:')\n",
    "print(f'MAE:  {mean_absolute_error(y_test_Student, Student_predict)} \\n'\n",
    "      f'RMSE: {np.sqrt(mean_squared_error(y_test_Student, Student_predict))} \\n'\n",
    "      f'MAPE: {mean_absolute_percentage_error(y_test_Student, Student_predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f331458-3ce1-492d-86f2-fa26792dd48f",
   "metadata": {},
   "source": [
    "### Метрики Имплементированной модели - Классификации качества Вина на новом бейзлайне\n",
    "Метрики Имплементированной модели на новом бейзлайне - Модель себя показала хуже прошлого бейзлайна. Метрики упали примерно на 0.1, что является плохим результатом. Тоже самое произошло и с моделью из sklearn, там на новом безлайне метрики так же упали на 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e77c0dd-e149-4feb-b362-c74d77473d85",
   "metadata": {},
   "source": [
    "### Метрики Метрики Имплементированной модели - Регрессии по экзаменам студентов на первом бейзлайне\n",
    "Метрики Имплементированной модели на новом бейзлайне - Модель на задач регрессии показала идентично прошлому безлайну, ничего не поменялось"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe8cd3d-a9a0-4c2d-bd1a-d790eed562bc",
   "metadata": {},
   "source": [
    "# Вывод по проделанной работе"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8799e029-09f0-4223-8658-e0b36b561596",
   "metadata": {},
   "source": [
    "В ходе лабораторной работы мы работали с двумя датасетами - Данные на задачу много классовой классификации, оценить качество вина, вторая задача Регрессионного характера, предсказать результаты студентов исходя из их привычек и поведения студентов. В данной лабораторной работе мы изучили такой алгоритм машинного обучения как Градиентный бустинг, проверили его работоспособность на задаче как классификации, так и регрессии, провели небольшое исследования при каких условиях модель показывает себя с лучшей стороны. Лучшим из возможных стала модель из sklearn на базовом безлайне. Оно и справедливо, данная модель не нуждается в масштабировании данных, а так же не особо сильно ругается при дисбалансе классов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4e6638-a3e6-4fab-b940-69bda94782b5",
   "metadata": {},
   "source": [
    "# Общий вывод по всем работам "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c57a37-5420-4cd0-b1af-0c60a15795b7",
   "metadata": {},
   "source": [
    "В ходе выполнения всех пяти лабораторных работ мы познакомились с такими моделями как: Ближайшие соседи, Линейная-Логистическая регрессии, Дерево решений, Случайный лес и Градиентный бустинг, а так же провели исследования для каждой из модели на двух датасетах: Датасет много классовой классификации по качеству вина и регрессионная задача по оценкам студентов. В первой лабораторной работе мы работали с Методом ближайших соседей, а так же провели небольшой анализ данных. Посмотрели на распределение классов в классификации (проверка на дисбаланс), просмотрели корреляцию между признаками в обоих датасетах и посмотрели распределение целевой переменной в задачи регрессии, вся эта информаци нужна нам была для проведения второго безлайна для каждой из моделей, где мы полноценно обработали наши данные и устранили изъяны датасетов. Модели же проверялись на двух безлайнах: Первый - простая кодировка данных и ничего больше, Второй - Препроцессинг данных, это устраннение дисбаланса классов, масштабирование данных, а так же подбор гиперпараметров и применение кросс-валидации к моделям. Далее мы имплементировали модели (Ручное их написание) и проверяли так же работоспособность на обоих безлайнах. Среди всех моделей достойнее всех себя показали следующие модели:\n",
    "- На задаче регрессии все модели, кроме KNN, показали себя достойно, но отдаём предпочтение Линейной регрессии, тк это самая лёгкая модель из всех.\n",
    "- На задаче Классификации всё сложнее, все модели по метрикам справились не очень хорошо, связано это скорее всего с самими данными, но лучше всех справилась модель Случайного леса, выбив частоту правильных предсказаний равное 0.67, получили мы это на базовом безлайне, а не на втором. Связано это с тем, что Ансамбль случайный лес строится из множества обычных моделей дерева решений, которые очень устойчивы к дисбалансу классов, а так же не нуждаются в масштабированни данных."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
